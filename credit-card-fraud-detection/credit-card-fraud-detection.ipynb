{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imort libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "file_path = \"../Data/raw/creditcard.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Columns: 31 entries, Time to Class\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Metadata information\n",
    "data.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicates\n",
    "data.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_na = data.isnull().sum() \n",
    "missing_na[missing_na > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X = data.drop(labels=['Time', 'Class'], axis=1)\n",
    "y = data['Class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation and test dataset\n",
    "X_full_train, X_test, y_full_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_full_train, y_full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of Amount variable\n",
    "plt.figure(figsize=(7, 4.5))\n",
    "sns.histplot(data=X_train, x='Amount', bins=20)\n",
    "plt.title(\"Amount Distribution\", size=11);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273745</th>\n",
       "      <td>-35.548539</td>\n",
       "      <td>-31.850484</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>15.304184</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>-27.34736</td>\n",
       "      <td>-3.872425</td>\n",
       "      <td>-12.005487</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.49772</td>\n",
       "      <td>-21.62012</td>\n",
       "      <td>5.712303</td>\n",
       "      <td>-1.581098</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>4.554683</td>\n",
       "      <td>3.415636</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>25691.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2         V3         V4          V5         V6  \\\n",
       "273745 -35.548539 -31.850484 -48.325589  15.304184 -113.743307  73.301626   \n",
       "\n",
       "                V7        V8        V9        V10  ...       V20       V21  \\\n",
       "273745  120.589494 -27.34736 -3.872425 -12.005487  ... -54.49772 -21.62012   \n",
       "\n",
       "             V22       V23       V24       V25       V26        V27  \\\n",
       "273745  5.712303 -1.581098  4.584549  4.554683  3.415636  31.612198   \n",
       "\n",
       "              V28    Amount  \n",
       "273745 -15.430084  25691.16  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for records with maximum value of amount\n",
    "max_value = X_train.Amount.max()\n",
    "X_train.loc[X_train.Amount == max_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31645"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for records greater than 100\n",
    "X_train.loc[X_train.Amount > 100].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the outliers\n",
    "def remove_outlier(col, data):\n",
    "\n",
    "    Q1 = np.quantile(data[col], q=0.25)\n",
    "    Q3 = np.quantile(data[col], q=0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Compute upper and lower range\n",
    "    upper_range = Q3 + IQR*1.5\n",
    "    lower_range = Q1 - IQR*1.5\n",
    "\n",
    "    # Filter the data for above range\n",
    "    data[col] = np.where(data[col] > upper_range, upper_range, data[col])\n",
    "    data[col] = np.where(data[col] < lower_range, lower_range, data[col])\n",
    "\n",
    "    return data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "            'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "            'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "\n",
    "for col in features:\n",
    "    X_train[col] = remove_outlier(col, X_train)\n",
    "    X_val[col] = remove_outlier(col, X_val)\n",
    "    X_test[col] = remove_outlier(col, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the model on training data\n",
    "scaler = scaler.fit(X_train, y_train)\n",
    "\n",
    "# Transform data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert them into dataframe\n",
    "X_train_ = pd.DataFrame(X_train_scaled, columns=features)\n",
    "X_val_ = pd.DataFrame(X_val_scaled, columns=features)\n",
    "X_test_ = pd.DataFrame(X_test_scaled, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR fitting on training data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fitting on training data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     classifiers_scores\u001b[38;5;241m.\u001b[39mappend((name, np\u001b[38;5;241m.\u001b[39mmean(scores)))\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1-Score for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m classifier:: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(scores)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +-(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(scores)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Personal_Work\\ML\\01_Projects\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\Personal_Work\\ML\\01_Projects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Personal_Work\\ML\\01_Projects\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\Personal_Work\\ML\\01_Projects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Personal_Work\\ML\\01_Projects\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Personal_Work\\ML\\01_Projects\\venv\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Personal_Work\\ML\\01_Projects\\venv\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Personal_Work\\ML\\01_Projects\\venv\\lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model selection\n",
    "models = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'RF': RandomForestClassifier(random_state=42),\n",
    "    'GB': GradientBoostingClassifier(random_state=42),\n",
    "    'ET': ExtraTreesClassifier(random_state=42),\n",
    "    'DT' : DecisionTreeClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'NB' : GaussianNB(),\n",
    "    'XGB': XGBClassifier(random_state=42) \n",
    "}\n",
    "\n",
    "classifiers_scores = []\n",
    "for name, model in models.items():\n",
    "    print(f'{name} fitting on training data...')\n",
    "    scores = cross_val_score(estimator=model, X=X_train_, y=y_train, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "    classifiers_scores.append((name, np.mean(scores)))\n",
    "    print(f'F1-Score for {name} classifier:: {np.mean(scores)} +-({np.std(scores)})')\n",
    "    print('---' * 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier\n",
    "\n",
    "XGBoost classifier performs best with 92% accuracy. So, let's further evaluate the performance of model using XGBClassifier.\n",
    "\n",
    "Test the model on validation data to ensure that model does not overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model to check overfitting.\n",
    "xgb_clf = XGBClassifier(max_depth=3, random_state=42)\n",
    "xgb_clf = xgb_clf.fit(X_train_, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = xgb_clf.predict(X_val_)\n",
    "y_train_preds = xgb_clf.predict(X_train_)\n",
    "\n",
    "# Compute the accuracy - Training\n",
    "train_recall = recall_score(y_train, y_train_preds)\n",
    "train_f1score = f1_score(y_train, y_train_preds)\n",
    "train_report = classification_report(y_train, y_train_preds)\n",
    "\n",
    "# on Validation\n",
    "recall = recall_score(y_val, y_preds)\n",
    "f1score = f1_score(y_val, y_preds)\n",
    "report = classification_report(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score\n",
      "Training :: 0.970\n",
      "Validation :: 0.789\n",
      "------------------------------\n",
      "F1-Score\n",
      "Training :: 0.981\n",
      "Validation :: 0.866\n"
     ]
    }
   ],
   "source": [
    "# Recall Score\n",
    "print(\"Recall Score\")\n",
    "print('Training :: %.3f' %train_recall)\n",
    "print('Validation :: %.3f' %recall)\n",
    "print(\"---\" * 10)\n",
    "# F1-Score\n",
    "print(\"F1-Score\")\n",
    "print('Training :: %.3f' %train_f1score)\n",
    "print('Validation :: %.3f' %f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    159324\n",
      "           1       0.99      0.97      0.98       271\n",
      "\n",
      "    accuracy                           1.00    159595\n",
      "   macro avg       1.00      0.99      0.99    159595\n",
      "weighted avg       1.00      1.00      1.00    159595\n",
      "\n",
      "------------------------------\n",
      "Validation Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     53109\n",
      "           1       0.96      0.79      0.87        90\n",
      "\n",
      "    accuracy                           1.00     53199\n",
      "   macro avg       0.98      0.89      0.93     53199\n",
      "weighted avg       1.00      1.00      1.00     53199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Report::\\n\", train_report)\n",
    "print(\"---\" * 10)\n",
    "print(\"Validation Report::\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    99.83329\n",
       "1     0.16671\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset is highly imbalance as it contain 99.8% of genuine transactions and only 0.1% fradualent transactions.\n",
    "\n",
    "Imbalance data causes ovefitting, which leads to inaccurate predictions on new unseen data. \n",
    "\n",
    "We can observed in our clasification scores for training and validation dataset. Here, the recall accuracy for class 1 in training data is 97% which drop to 79% for validation data indicating overfitting model, unable to find true patterns and relationship between the features and dependent variable.\n",
    "\n",
    "To avoid overfitting, we can apply:\n",
    "- Resampling methods.\n",
    "- Adjust the class weight parameters of algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    \n",
    "    recallScore = recall_score(y_true, y_pred)\n",
    "    f1Score = f1_score(y_true, y_pred)\n",
    "    precisionScore = precision_score(y_true, y_pred)\n",
    "    classifier_report = classification_report(y_true, y_pred)\n",
    "\n",
    "    return recallScore, f1Score, precisionScore, classifier_report\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(model):\n",
    "\n",
    "    # fit the model on training data\n",
    "    model = model.fit(X_train_, y_train)\n",
    "    \n",
    "    # make predictions on training and validation data\n",
    "    y_train_preds = model.predict(X_train_)\n",
    "    y_val_preds = model.predict(X_val_)\n",
    "\n",
    "    # Training scores\n",
    "    train_recall, train_f1score, train_precision, train_report = get_score(y_train, y_train_preds)\n",
    "    val_recall, val_f1score, val_precision, val_report = get_score(y_val, y_val_preds)\n",
    "\n",
    "    # Recall Score\n",
    "    print(\"Recall Score\")\n",
    "    print('Training :: %.3f' %train_recall)\n",
    "    print('Validation :: %.3f' %val_recall)\n",
    "    print(\"---\" * 10)\n",
    "\n",
    "    # Precision Score\n",
    "    print(\"Precision Score\")\n",
    "    print('Training :: %.3f' %train_precision)\n",
    "    print('Validation :: %.3f' %val_precision)\n",
    "    print(\"---\" * 10)\n",
    "    \n",
    "    # F1-Score\n",
    "    print(\"F1-Score\")\n",
    "    print('Training :: %.3f' %train_f1score)\n",
    "    print('Validation :: %.3f' %val_f1score)\n",
    "\n",
    "    print(\"---\" * 10)\n",
    "    print(\"Training Report::\\n\", train_report)\n",
    "    print(\"---\" * 10)\n",
    "    print(\"Validation Report::\\n\", val_report)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcuate the class weight\n",
    "positive_instances = sum(y_train == 1)\n",
    "negative_instances = sum(y_train == 0)\n",
    "\n",
    "scale_pos_weight_value =  negative_instances / positive_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score\n",
      "Training :: 1.000\n",
      "Validation :: 0.833\n",
      "------------------------------\n",
      "Precision Score\n",
      "Training :: 0.749\n",
      "Validation :: 0.708\n",
      "------------------------------\n",
      "F1-Score\n",
      "Training :: 0.856\n",
      "Validation :: 0.765\n",
      "------------------------------\n",
      "Training Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    159324\n",
      "           1       0.75      1.00      0.86       271\n",
      "\n",
      "    accuracy                           1.00    159595\n",
      "   macro avg       0.87      1.00      0.93    159595\n",
      "weighted avg       1.00      1.00      1.00    159595\n",
      "\n",
      "------------------------------\n",
      "Validation Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     53109\n",
      "           1       0.71      0.83      0.77        90\n",
      "\n",
      "    accuracy                           1.00     53199\n",
      "   macro avg       0.85      0.92      0.88     53199\n",
      "weighted avg       1.00      1.00      1.00     53199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set class weight parameters\n",
    "# Create model instance\n",
    "xgb_model = XGBClassifier(n_estimators=100, \n",
    "                          max_depth=3, \n",
    "                          scale_pos_weight=scale_pos_weight_value, \n",
    "                          n_jobs = -1, random_state=42)\n",
    "\n",
    "# Model evaluation\n",
    "xgb_model = eval_model(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score\n",
      "Training :: 1.000\n",
      "Validation :: 0.889\n",
      "------------------------------\n",
      "Precision Score\n",
      "Training :: 0.263\n",
      "Validation :: 0.255\n",
      "------------------------------\n",
      "F1-Score\n",
      "Training :: 0.417\n",
      "Validation :: 0.396\n",
      "------------------------------\n",
      "Training Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    159324\n",
      "           1       0.26      1.00      0.42       271\n",
      "\n",
      "    accuracy                           1.00    159595\n",
      "   macro avg       0.63      1.00      0.71    159595\n",
      "weighted avg       1.00      1.00      1.00    159595\n",
      "\n",
      "------------------------------\n",
      "Validation Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     53109\n",
      "           1       0.25      0.89      0.40        90\n",
      "\n",
      "    accuracy                           1.00     53199\n",
      "   macro avg       0.63      0.94      0.70     53199\n",
      "weighted avg       1.00      1.00      1.00     53199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set parameter: Learning Rate = 0.1\n",
    "xgb_model_02 = XGBClassifier(n_estimators=100, \n",
    "                          learning_rate=0.1,\n",
    "                          max_depth=3, \n",
    "                          scale_pos_weight=scale_pos_weight_value, \n",
    "                          n_jobs = -1, random_state=42)\n",
    "\n",
    "# Model evaluation\n",
    "xgb_model_02 = eval_model(xgb_model_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score\n",
      "Training :: 0.923\n",
      "Validation :: 0.844\n",
      "------------------------------\n",
      "Precision Score\n",
      "Training :: 0.067\n",
      "Validation :: 0.063\n",
      "------------------------------\n",
      "F1-Score\n",
      "Training :: 0.125\n",
      "Validation :: 0.117\n",
      "------------------------------\n",
      "Training Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    159324\n",
      "           1       0.07      0.92      0.13       271\n",
      "\n",
      "    accuracy                           0.98    159595\n",
      "   macro avg       0.53      0.95      0.56    159595\n",
      "weighted avg       1.00      0.98      0.99    159595\n",
      "\n",
      "------------------------------\n",
      "Validation Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     53109\n",
      "           1       0.06      0.84      0.12        90\n",
      "\n",
      "    accuracy                           0.98     53199\n",
      "   macro avg       0.53      0.91      0.55     53199\n",
      "weighted avg       1.00      0.98      0.99     53199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update Learning Rate to 0.01\n",
    "xgb_model_02 = XGBClassifier(n_estimators=100, \n",
    "                            learning_rate=0.01,\n",
    "                            max_depth=3, \n",
    "                            scale_pos_weight=scale_pos_weight_value, \n",
    "                            n_jobs = -1, \n",
    "                            random_state=42)\n",
    "\n",
    "# Model evaluation\n",
    "xgb_model_02 = eval_model(xgb_model_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score\n",
      "Training :: 0.923\n",
      "Validation :: 0.844\n",
      "------------------------------\n",
      "Precision Score\n",
      "Training :: 0.067\n",
      "Validation :: 0.063\n",
      "------------------------------\n",
      "F1-Score\n",
      "Training :: 0.125\n",
      "Validation :: 0.117\n",
      "------------------------------\n",
      "Training Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    159324\n",
      "           1       0.07      0.92      0.13       271\n",
      "\n",
      "    accuracy                           0.98    159595\n",
      "   macro avg       0.53      0.95      0.56    159595\n",
      "weighted avg       1.00      0.98      0.99    159595\n",
      "\n",
      "------------------------------\n",
      "Validation Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     53109\n",
      "           1       0.06      0.84      0.12        90\n",
      "\n",
      "    accuracy                           0.98     53199\n",
      "   macro avg       0.53      0.91      0.55     53199\n",
      "weighted avg       1.00      0.98      0.99     53199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set Parameter - subsample= 0.6\n",
    "xgb_model_03 = XGBClassifier(n_estimators=200, \n",
    "                                learning_rate=0.01,\n",
    "                                subsample=0.6,\n",
    "                                max_depth=3, \n",
    "                                scale_pos_weight=scale_pos_weight_value, \n",
    "                                n_jobs = -1, \n",
    "                                random_state=42)\n",
    "\n",
    "# Model evaluation\n",
    "xgb_model_03 = eval_model(xgb_model_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=42, ...),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(3, 9, 2),\n",
       "                                        &#x27;n_estimators&#x27;: range(100, 1201)},\n",
       "                   random_state=42, scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=42, ...),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: range(3, 9, 2),\n",
       "                                        &#x27;n_estimators&#x27;: range(100, 1201)},\n",
       "                   random_state=42, scoring=&#x27;f1_macro&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1168, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1168, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           multi_strategy=None,\n",
       "                                           n_estimators=None, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=42, ...),\n",
       "                   param_distributions={'max_depth': range(3, 9, 2),\n",
       "                                        'n_estimators': range(100, 1201)},\n",
       "                   random_state=42, scoring='f1_macro')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': range(100, 1201),\n",
    "    'max_depth': range(3, 9, 2)\n",
    "}\n",
    "\n",
    "XGB_clf = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.1, \n",
    "    scale_pos_weight=scale_pos_weight_value,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_searchCV = RandomizedSearchCV(estimator=XGB_clf, \n",
    "                                    param_distributions=params, \n",
    "                                    random_state=42, scoring='f1_macro',\n",
    "                                    cv=5)\n",
    "\n",
    "# Fit on the training data\n",
    "random_searchCV.fit(X_train_, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score\n",
      "Training :: 1.000\n",
      "Validation :: 0.800\n",
      "------------------------------\n",
      "Precision Score\n",
      "Training :: 1.000\n",
      "Validation :: 0.935\n",
      "------------------------------\n",
      "F1-Score\n",
      "Training :: 1.000\n",
      "Validation :: 0.862\n",
      "------------------------------\n",
      "Training Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    159324\n",
      "           1       1.00      1.00      1.00       271\n",
      "\n",
      "    accuracy                           1.00    159595\n",
      "   macro avg       1.00      1.00      1.00    159595\n",
      "weighted avg       1.00      1.00      1.00    159595\n",
      "\n",
      "------------------------------\n",
      "Validation Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     53109\n",
      "           1       0.94      0.80      0.86        90\n",
      "\n",
      "    accuracy                           1.00     53199\n",
      "   macro avg       0.97      0.90      0.93     53199\n",
      "weighted avg       1.00      1.00      1.00     53199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation on final model\n",
    "final_model = random_searchCV.best_estimator_\n",
    "final_model = eval_model(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data\n",
    "X_ = pd.concat([X_train_, X_val_])\n",
    "y_ = pd.concat([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((212794, 29), (212794,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape, y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:: 0.786\n",
      "F1 Score:: 0.838\n",
      "Precision Score:: 0.898\n",
      "Report::\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70820\n",
      "           1       0.90      0.79      0.84       112\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.95      0.89      0.92     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's find the model performance on test data\n",
    "final_model = random_searchCV.best_estimator_\n",
    "final_model = final_model.fit(X_, y_)\n",
    "predictions = final_model.predict(X_test_)\n",
    "\n",
    "recallScore, f1Score, precisionScore, classifier_report = get_score(y_test, predictions)\n",
    "\n",
    "print('Recall Score:: %.3f' %recallScore)\n",
    "print('F1 Score:: %.3f' %f1Score)\n",
    "print('Precision Score:: %.3f' %precisionScore)\n",
    "print(f'Report::\\n {classifier_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no big difference between the validation and final scores.\n",
    "\n",
    "This model has 90% of precision, 79% of recall and 84% of f1 score accuracy, which can be still a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "model_file = \"../Models/XGB_Classifier.bin\"\n",
    "\n",
    "with open(model_file, 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "    print(\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
